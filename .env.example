# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3:3b

# Hardware Configuration
USE_GPU=true
HARDWARE_MODE=auto  # auto, gpu, or cpu

# Model Configuration
TEMPERATURE=0.7
MAX_TOKENS=2048

# Application Configuration
PORT=7860
HOST=0.0.0.0

# Project Settings
DEFAULT_ROUNDS=3
