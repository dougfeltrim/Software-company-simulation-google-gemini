# CrewAI Service Environment Variables

# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
DEFAULT_MODEL=llama3

# Server Configuration
PORT=3002
WS_PORT=3003
