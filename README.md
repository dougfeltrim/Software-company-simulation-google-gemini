# üè¢ AI Software Company Simulation

> **Create complete software projects with AI agents powered by Ollama, CrewAI, and local LLMs**

This project simulates a software company where multiple AI agents collaborate to develop complete projects, generating code and documentation ready for the client. Now with **local execution**, **GPU/CPU support**, and a **ChatGPT-like interface**!

## ‚ú® New Features

- üöÄ **Fully Local Execution** - Runs completely on your machine using Ollama
- ü§ñ **CrewAI Integration** - Advanced multi-agent orchestration
- üíª **GPU & CPU Support** - Automatic hardware detection and optimization
- üìä **System Benchmark** - Automatically selects optimal models for your hardware
- üé® **ChatGPT-like Interface** - Modern web UI built with Gradio
- üê≥ **Docker Support** - Easy deployment with Docker Compose
- üîß **Flexible Configuration** - Customize models, temperature, and more

## üìã Table of Contents

- [Features](#features)
- [Requirements](#requirements)
- [Quick Start](#quick-start)
- [Usage](#usage)
- [Available Models](#available-models)
- [Architecture](#architecture)
- [Original Version](#original-version)
- [Contributing](#contributing)

## üéØ Features

### AI Agents

The system includes 7 specialized AI agents that work in parallel:

1. **Product Manager** - Defines requirements, splits tasks for parallel work
2. **Software Architect** - Designs modular architecture with clear component boundaries
3. **Backend Developer** - Develops server-side components in parallel
4. **Frontend Developer** - Develops client-side components in parallel
5. **Integration Engineer** - Tests component connections and identifies integration issues
6. **QA Engineer** - Validates quality and coordinates issue resolution
7. **Technical Writer** - Documents everything clearly

### Technical Features

- ‚úÖ **100% Local** - No API keys or cloud services needed
- ‚úÖ **Parallel Agent Collaboration** - Agents work on different components simultaneously
- ‚úÖ **Automatic Integration Testing** - Components are tested and integrated automatically
- ‚úÖ **Collaborative Problem Solving** - Agents discuss and resolve integration issues together
- ‚úÖ **Hardware Optimization** - Automatically detects and uses GPU if available
- ‚úÖ **Model Selection** - Recommends best models for your hardware
- ‚úÖ **Web Interface** - Easy-to-use ChatGPT-like interface
- ‚úÖ **CLI Mode** - Command-line interface for automation
- ‚úÖ **Docker Support** - Containerized deployment
- ‚úÖ **Benchmark Tool** - Test your system capabilities

## üíª Requirements

### Minimum Requirements

- **Docker** and **Docker Compose**
- **8GB RAM** (minimum)
- **20GB free disk space**
- **Linux, macOS, or Windows** with WSL2

### Recommended Requirements

- **16GB+ RAM**
- **NVIDIA GPU** with 6GB+ VRAM (optional, but recommended)
- **NVIDIA Container Toolkit** (for GPU support)

### Software Requirements

- Docker 20.10+
- Docker Compose 2.0+
- NVIDIA drivers (if using GPU)

## üöÄ Quick Start

### For Docker Users (Recommended)

1. **Clone the repository**
   ```bash
   git clone https://github.com/dougfeltrim/Software-company-simulation-google-gemini.git
   cd Software-company-simulation-google-gemini
   ```

2. **Run setup**
   ```bash
   ./setup.sh
   ```

3. **Start the services**
   ```bash
   # Auto-detect GPU/CPU
   ./start.sh
   
   # Or force CPU mode
   ./start.sh cpu
   ```

4. **Pull a model**
   ```bash
   ./pull-model.sh llama3:3b
   ```

5. **Access the web interface at http://localhost:7860**

### For Local Python Users

```bash
pip install -r requirements.txt
ollama pull llama3:3b
python main.py interface
```

## üìñ Usage

### Web Interface
1. Access http://localhost:7860
2. Select a model from the dropdown
3. Enter your project description
4. Click "Generate Project"
5. Review output and download

### CLI Mode
```bash
python main.py cli --description "Build a calculator app"
```

### System Benchmark
```bash
python main.py benchmark
```

## ü§ñ Available Models

- `llama3:8b` - Best quality (needs 8GB+ VRAM)
- `llama3:3b` - Recommended default
- `mistral:7b` - Excellent balance
- `phi3:mini` - Fast and efficient
- `gemma:2b` - Lightweight
- `tinyllama:1.1b` - Very fast (CPU)

## üîß Configuration

Edit `.env` file:
```env
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3:3b
TEMPERATURE=0.7
PORT=7860
```

## üîç Troubleshooting

**Ollama not starting:**
```bash
docker ps
docker logs ollama
docker restart ollama
```

**Model not found:**
```bash
./pull-model.sh llama3:3b
```

**Out of memory:** Use a smaller model like `tinyllama:1.1b`

---

## üìñ Original Version

**Selecione o idioma desejado abaixo para visualizar as instru√ß√µes completas em Portugu√™s ou Ingl√™s.**  

**Select the desired language below to view the full instructions in Portuguese or English.**

<details>
<summary><strong>Portugu√™s (Brasil)</strong></summary>

## Ferramentas Necess√°rias
- Google Colab
- Chave da API do Google Gemini: Voc√™ pode obter sua chave em [https://ai.google.dev/gemini-api/docs/api-key?hl=pt-br](https://ai.google.dev/gemini-api/docs/api-key?hl=pt-br).

## Como Executar
1. No Google Colab, acesse o √≠cone de chave no menu lateral esquerdo.
2. Adicione um novo "secret" com o nome `GOOGLE_API_KEY` e cole sua chave da API no campo "valor".
3. Na vari√°vel `project_description`, substitua o valor pela descri√ß√£o do software que deseja criar. Por exemplo:
   - "Desenvolver um script de calculadora para ser executado no terminal".

## Como Funciona
Este c√≥digo Python simula uma empresa de software que utiliza diferentes agentes de IA (como Gerente de Produto, Arquiteto de Software, Desenvolvedor, Redator T√©cnico e Sintetizador de Projeto) para colaborar na cria√ß√£o de um projeto de software.

### Configura√ß√£o Inicial
O c√≥digo come√ßa configurando a chave da API do Google Gemini, que √© usada para interagir com o modelo de IA gemini-2.0-flash.

### Classe Agent
A classe `Agent` representa um membro da equipe de software. Cada agente possui:
- `name`: Um nome para o agente (por exemplo, "Gerente de Produto").
- `system_instruction`: Uma instru√ß√£o que define o papel do agente e seu foco (por exemplo, "Voc√™ define os requisitos do software e a vis√£o do produto."). Esta instru√ß√£o √© crucial para guiar o comportamento do modelo de IA.
- `history`: Uma lista para armazenar o hist√≥rico de intera√ß√µes (prompts e respostas) do agente.

O m√©todo `generate_response` √© respons√°vel por enviar um prompt ao modelo Gemini. Ele incorpora a `system_instruction` do agente para garantir que a resposta seja relevante ao seu papel, e define `max_output_tokens` para controlar o tamanho da resposta e `temperature` (0.7 para respostas mais focadas).

### Classe SoftwareCompany
A classe `SoftwareCompany` orquestra a colabora√ß√£o entre os diferentes agentes.
- `__init__`: Inicializa a empresa criando inst√¢ncias de cada `Agent` com seus respectivos nomes e instru√ß√µes.
- `generate_project(self, project_description, rounds=5)`: Este √© o m√©todo principal que simula o processo de desenvolvimento do projeto.
  - Ele recebe uma `project_description` (descri√ß√£o do projeto) e o n√∫mero de `rounds` (rodadas de intera√ß√£o) para a colabora√ß√£o.
  - Em cada rodada, os agentes (exceto o Project Synthesizer inicialmente) geram respostas com base na `current_task` (tarefa atual).
  - O Project Synthesizer entra em a√ß√£o para consolidar as respostas dos outros agentes, criando uma nova `current_task` que avan√ßa o projeto.
  - Nas √∫ltimas rodadas (definido por `rounds - 2`), o c√≥digo instrui o Developer a gerar o c√≥digo Python e o Technical Writer a criar a documenta√ß√£o t√©cnica, baseando-se na `current_task` e, no caso do redator, tamb√©m no c√≥digo gerado.
  - Finalmente, o Project Synthesizer faz uma consolida√ß√£o final de todo o trabalho, incluindo o c√≥digo e a documenta√ß√£o, para apresentar um "projeto final pronto para o cliente".

### Exemplo de Uso
No final do c√≥digo, uma inst√¢ncia da `SoftwareCompany` √© criada e o m√©todo `generate_project` √© chamado com uma descri√ß√£o de projeto (`project_description`) e um n√∫mero de rodadas (`rounds`). O exemplo abaixo mostra apenas 1 rodada, mas aumentar esse n√∫mero permitiria uma colabora√ß√£o mais profunda e, teoricamente, um projeto mais completo.

```python
company = SoftwareCompany()
project_description = "Desenvolver um script de calculadora para ser executado no terminal"
final_code, final_documentation = company.generate_project(project_description, rounds=3) # Ajuste o n√∫mero de rodadas conforme necess√°rio
```

## O Que Este C√≥digo Demonstra?
Este c√≥digo √© um exemplo pr√°tico de como a intelig√™ncia artificial generativa pode ser usada para simular e automatizar fluxos de trabalho colaborativos. Ao atribuir pap√©is e responsabilidades distintas a cada agente de IA, o sistema pode gerar componentes de software (como c√≥digo e documenta√ß√£o) de forma mais estruturada e relevante, imitando a intera√ß√£o de uma equipe humana. Ele explora o conceito de agentes aut√¥nomos trabalhando juntos para alcan√ßar um objetivo comum.

</details>

<details>
<summary><strong>English</strong></summary>

## Project: Software Company Using AI Agents

This project simulates a software company where AI agents collaborate to develop a complete project, including the final code and its documentation, ready for the client.

### Required Tools
- Google Colab
- Google Gemini API Key: You can get your key at [https://ai.google.dev/gemini-api/docs/api-key](https://ai.google.dev/gemini-api/docs/api-key).

### How to Run
1. In Google Colab, access the key icon in the left-hand sidebar menu.
2. Add a new "secret" named `GOOGLE_API_KEY` and paste your API key into the "value" field.
3. In the `project_description` variable, replace the value with the description of the software you want to create. For example:
   - "Develop a calculator script to be executed in the terminal".

### How It Works
This Python code simulates a software company that uses various AI agents (such as Product Manager, Software Architect, Developer, Technical Writer, and Project Synthesizer) to collaborate on creating a software project.

#### Initial Setup
The code begins by configuring the Google Gemini API key, which is used to interact with the gemini-2.0-flash AI model.

#### Agent Class
The `Agent` class represents a member of the software team. Each agent has:
- `name`: A name for the agent (e.g., "Product Manager").
- `system_instruction`: An instruction that defines the agent's role and focus (e.g., "You define the software requirements and product vision."). This instruction is crucial for guiding the AI model's behavior.
- `history`: A list to store the agent's interaction history (prompts and responses).

The `generate_response` method is responsible for sending a prompt to the Gemini model. It incorporates the agent's `system_instruction` to ensure the response is relevant to its role and sets `max_output_tokens` to control the response length, and `temperature` (0.7 for more focused responses).

#### SoftwareCompany Class
The `SoftwareCompany` class orchestrates the collaboration among the different agents.
- `__init__`: Initializes the company by creating instances of each `Agent` with their respective names and instructions.
- `generate_project(self, project_description, rounds=5)`: This is the main method that simulates the project development process.
  - It takes a `project_description` and the number of rounds of interaction for the collaboration.
  - In each round, the agents (except the Project Synthesizer initially) generate responses based on the `current_task`.
  - The Project Synthesizer then consolidates the responses from the other agents, creating a new `current_task` that advances the project.
  - In the final rounds (defined by `rounds - 2`), the code instructs the Developer to generate the Python code and the Technical Writer to create the technical documentation, based on the `current_task` and, in the writer's case, also the code generated.
  - Finally, the Project Synthesizer performs a final consolidation of all the work, including code and documentation, to present a "final project ready for the client."

#### Example Usage
At the end of the code, a `SoftwareCompany` instance is created, and the `generate_project` method is called with a project description (`project_description`) and a number of rounds (`rounds`). The example below shows only 1 round, but increasing this number would allow for deeper collaboration and, theoretically, a more complete project.

```python
company = SoftwareCompany()
project_description = "Develop a calculator script to be executed in the terminal"
final_code, final_documentation = company.generate_project(project_description, rounds=3) # Adjust the number of rounds as needed
```

### What This Code Demonstrates
This code is a practical example of how generative artificial intelligence can be used to simulate and automate collaborative workflows. By assigning distinct roles and responsibilities to each AI agent, the system can generate software components (like code and documentation) in a more structured and relevant way, mimicking the interaction of a human team. It explores the concept of autonomous agents working together to achieve a common goal.

</details>